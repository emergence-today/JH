"""
é…ç½®æ–‡ä»¶ - ç³»çµ±è¨­å®šå’Œåƒæ•¸
"""

import os
from typing import Dict, List
from dotenv import load_dotenv

# è¼‰å…¥ .env æ–‡ä»¶
load_dotenv()

class Config:
    """ç³»çµ±é…ç½®é¡"""

    # Qdrant è¨­å®š
    QDRANT_URL = os.getenv("QDRANT_URL", "http://ec2-13-112-118-36.ap-northeast-1.compute.amazonaws.com:6333")
    QDRANT_COLLECTION_NAME = os.getenv("QDRANT_COLLECTION_NAME", "steven_JH")

    # OpenAI API è¨­å®š - å¾ .env è®€å–
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
    OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o")
    OPENAI_EMBEDDING_MODEL = os.getenv("OPENAI_EMBEDDING_MODEL", "text-embedding-3-large")

    # Zerox è¦–è¦ºè™•ç†æ¨¡å‹
    ZEROX_MODEL = os.getenv("ZEROX_MODEL", "gpt-4o")

    # AWS Bedrock è¨­å®š - å¾ .env è®€å–
    AWS_ACCESS_KEY_ID = os.getenv("AWS_ACCESS_KEY_ID", "")
    AWS_SECRET_ACCESS_KEY = os.getenv("AWS_SECRET_ACCESS_KEY", "")
    AWS_REGION = os.getenv("AWS_REGION", "us-east-1")
    BEDROCK_MODEL = os.getenv("BEDROCK_MODEL", "us.anthropic.claude-sonnet-4-20250514-v1:0")

    # RAGæª¢ç´¢åƒæ•¸ - å¾ .env è®€å–ï¼Œå¦‚æœæ²’æœ‰å‰‡ä½¿ç”¨é è¨­å€¼
    DEFAULT_TOP_K = int(os.getenv("TOP_K_RETRIEVAL", "3"))

    # èªè¨€æ¨¡å‹åƒæ•¸ - å¾ .env è®€å–
    MAX_TOKENS = int(os.getenv("MAX_TOKENS", "1000"))
    TEMPERATURE = float(os.getenv("TEMPERATURE", "0.7"))

    # LangChain è¨­å®š
    LANGCHAIN_VERBOSE = os.getenv("LANGCHAIN_VERBOSE", "false").lower() == "true"
    LANGCHAIN_CACHE = os.getenv("LANGCHAIN_CACHE", "true").lower() == "true"

    # è¨˜æ†¶ç®¡ç†è¨­å®š
    MEMORY_MAX_TOKENS = int(os.getenv("MEMORY_MAX_TOKENS", "8000"))
    MEMORY_WINDOW_SIZE = int(os.getenv("MEMORY_WINDOW_SIZE", "10"))  # ä¿ç•™æœ€è¿‘Nè¼ªå°è©±

    # å‘é‡æª¢ç´¢è¨­å®š
    EMBEDDING_DIMENSION = int(os.getenv("EMBEDDING_DIMENSION", "3072"))  # text-embedding-3-large

    # Chain è¨­å®š
    CHAIN_TYPE = os.getenv("CHAIN_TYPE", "stuff")  # stuff, map_reduce, refine, map_rerank
    RETURN_SOURCE_DOCUMENTS = os.getenv("RETURN_SOURCE_DOCUMENTS", "true").lower() == "true"

    # RAGç³»çµ±é¡å‹ - å›ºå®šä½¿ç”¨ LangChain
    RAG_SYSTEM_TYPE = "langchain"

    # API åŸºç¤ URL è¨­å®š
    API_BASE_URL = os.getenv("API_BASE_URL", "http://localhost:8006")

# ç’°å¢ƒè®Šæ•¸æª¢æŸ¥
def check_environment():
    """æª¢æŸ¥ç’°å¢ƒè®Šæ•¸å’Œä¾è³´"""
    issues = []
    
    # æª¢æŸ¥OpenAI API Key
    if not Config.OPENAI_API_KEY:
        issues.append("æœªè¨­å®š OPENAI_API_KEY ç’°å¢ƒè®Šæ•¸")

    return issues

if __name__ == "__main__":
    # æ¸¬è©¦é…ç½®
    issues = check_environment()
    if issues:
        print("âš ï¸ ç’°å¢ƒæª¢æŸ¥ç™¼ç¾å•é¡Œ:")
        for issue in issues:
            print(f"  - {issue}")
    else:
        print("âœ… ç’°å¢ƒæª¢æŸ¥é€šé")

    print(f"\nğŸ“‹ é…ç½®æ‘˜è¦:")
    print(f"  å‘é‡æ¨¡å‹: {Config.OPENAI_EMBEDDING_MODEL}")
    print(f"  Qdrant URL: {Config.QDRANT_URL}")
    print(f"  é›†åˆåç¨±: {Config.QDRANT_COLLECTION_NAME}")
