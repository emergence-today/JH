"""
FastAPI æœå‹™å™¨ - æä¾› RAG æŸ¥è©¢ API
æ”¯æ´ Qdrant çŸ¥è­˜åº«æª¢ç´¢å’Œåœ–ç‰‡ URL å›å‚³
"""

from fastapi import FastAPI, HTTPException, Query, UploadFile, File, Form
from fastapi.responses import JSONResponse, StreamingResponse, PlainTextResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
from contextlib import asynccontextmanager
import logging
import os
from pathlib import Path
import uvicorn
import tempfile
import shutil
import uuid
import time
import tiktoken
import json
import asyncio
import pandas as pd
import zipfile
import io


from src.core.langchain_rag_system import LangChainParentChildRAG
from config.config import Config
from src.processors.pdf_processor import PDFProcessor
from src.processors.file_converter import FileConverter

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å…¨åŸŸè®Šæ•¸
rag_system = None
memory_manager = None

# åœ–ç‰‡ç›®éŒ„è·¯å¾‘
IMAGES_DIR = "outputs/images/zerox_output"

@asynccontextmanager
async def lifespan(app: FastAPI):
    """æ‡‰ç”¨ç”Ÿå‘½é€±æœŸç®¡ç†"""
    # å•Ÿå‹•æ™‚åˆå§‹åŒ–
    global rag_system, memory_manager
    try:
        logger.info("æ­£åœ¨åˆå§‹åŒ– LangChain Parent-Child RAG ç³»çµ±...")
        rag_system = LangChainParentChildRAG(Config.QDRANT_COLLECTION_NAME)

        logger.info("LANGCHAIN RAG ç³»çµ±åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"  ç³»çµ±é¡å‹: {rag_system.get_system_info()['system_type']}")
        if hasattr(rag_system, 'child_collection_name'):
            logger.info(f"  å­æ®µè½é›†åˆ: {rag_system.child_collection_name}")
            logger.info(f"  çˆ¶æ®µè½é›†åˆ: {rag_system.parent_collection_name}")

        # åˆå§‹åŒ–è¨˜æ†¶ç®¡ç†å™¨
        memory_manager = MemoryManager()
        logger.info("è¨˜æ†¶ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")

        # æª¢æŸ¥åœ–ç‰‡ç›®éŒ„
        if os.path.exists(IMAGES_DIR):
            logger.info(f"åœ–ç‰‡ç›®éŒ„å­˜åœ¨: {IMAGES_DIR}/ - å°‡é€šé /images/{{filename}} ç«¯é»æä¾›")
        else:
            logger.warning(f"{IMAGES_DIR} ç›®éŒ„ä¸å­˜åœ¨")

    except Exception as e:
        logger.error(f"ç³»çµ±åˆå§‹åŒ–å¤±æ•—: {e}")
        raise

    yield

    # é—œé–‰æ™‚æ¸…ç†ï¼ˆå¦‚æœéœ€è¦ï¼‰
    logger.info("æ‡‰ç”¨é—œé–‰")

# åˆå§‹åŒ– FastAPI æ‡‰ç”¨
app = FastAPI(
    title="åœ–é¢è­˜åˆ¥æ•™å­¸ RAG API",
    description="åŸºæ–¼ Qdrant å‘é‡è³‡æ–™åº«çš„æ•™å­¸å‹ RAG æŸ¥è©¢æœå‹™",
    version="1.0.0",
    root_path="/api/v1/JH",
    lifespan=lifespan
)

# æ·»åŠ  CORS ä¸­é–“ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # åœ¨ç”Ÿç”¢ç’°å¢ƒä¸­æ‡‰è©²é™åˆ¶ç‰¹å®šåŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åœ–ç‰‡æª”æ¡ˆå°‡é€šéæ‰‹å‹•ç«¯é» /images/{filename} æä¾›
# ä¸ä½¿ç”¨ StaticFiles æ›è¼‰ï¼Œé¿å…èˆ‡ root_path è¡çª
# åœ–ç‰‡ç›®éŒ„æª¢æŸ¥å°‡åœ¨æ‡‰ç”¨å•Ÿå‹•æ™‚é€²è¡Œ

# è¨˜æ†¶ç®¡ç†ç³»çµ±
class MemoryManager:
    """èŠå¤©è¨˜æ†¶ç®¡ç†å™¨"""

    def __init__(self, max_tokens: int = 8000, model_name: str = "gpt-3.5-turbo"):
        self.sessions = {}  # å„²å­˜æ‰€æœ‰æœƒè©±çš„è¨˜æ†¶
        self.max_tokens = max_tokens
        self.model_name = model_name
        self.encoding = tiktoken.encoding_for_model(model_name)

    def get_session(self, session_id: str) -> List[Dict]:
        """ç²å–æœƒè©±è¨˜æ†¶"""
        if session_id not in self.sessions:
            self.sessions[session_id] = [
                {
                    "role": "system",
                    "content": """ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å“ç®¡æ•™è‚²è¨“ç·´è¬›å¸«åŠ©æ‰‹ï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹é»ï¼š
1. èƒ½å¤ è¨˜ä½å°è©±æ­·å²ï¼Œæä¾›é€£è²«çš„å°è©±é«”é©—
2. åŸºæ–¼æä¾›çš„æ•™æå…§å®¹å›ç­”å•é¡Œ
3. ç”¨æ¸…æ¥šã€å‹å–„çš„æ–¹å¼è§£é‡‹æŠ€è¡“æ¦‚å¿µ
4. æœƒåƒè€ƒä¹‹å‰çš„å°è©±å…§å®¹ä¾†æä¾›æ›´å€‹äººåŒ–çš„å›ç­”
5. ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”å•é¡Œ"""
                }
            ]
        return self.sessions[session_id]

    def add_message(self, session_id: str, role: str, content: str):
        """æ·»åŠ è¨Šæ¯åˆ°æœƒè©±è¨˜æ†¶"""
        messages = self.get_session(session_id)
        messages.append({"role": role, "content": content})

        # æª¢æŸ¥tokené™åˆ¶ä¸¦æ¸…ç†è¨˜æ†¶
        self._manage_memory(session_id)

    def _calculate_tokens(self, messages: List[Dict]) -> int:
        """è¨ˆç®—è¨Šæ¯åˆ—è¡¨çš„tokenæ•¸é‡"""
        total_tokens = 0
        for msg in messages:
            total_tokens += len(self.encoding.encode(msg["content"]))
        return total_tokens

    def _manage_memory(self, session_id: str):
        """ç®¡ç†è¨˜æ†¶ï¼Œé¿å…è¶…étokené™åˆ¶"""
        messages = self.sessions[session_id]
        total_tokens = self._calculate_tokens(messages)

        # å¦‚æœè¶…éé™åˆ¶ï¼Œç§»é™¤æ—©æœŸçš„å°è©±ï¼ˆä¿ç•™system messageï¼‰
        while total_tokens > self.max_tokens and len(messages) > 1:
            # ç§»é™¤æœ€æ—©çš„ç”¨æˆ¶æˆ–åŠ©æ‰‹è¨Šæ¯ï¼ˆä¿ç•™system messageï¼‰
            if len(messages) > 1:
                messages.pop(1)
                total_tokens = self._calculate_tokens(messages)

        logger.info(f"æœƒè©± {session_id} ç›®å‰tokenæ•¸é‡: {total_tokens}")

    def get_session_summary(self, session_id: str) -> Dict:
        """ç²å–æœƒè©±æ‘˜è¦è³‡è¨Š"""
        if session_id not in self.sessions:
            return {"exists": False}

        messages = self.sessions[session_id]
        return {
            "exists": True,
            "message_count": len(messages) - 1,  # æ‰£é™¤system message
            "total_tokens": self._calculate_tokens(messages),
            "last_activity": time.time()
        }

    def clear_session(self, session_id: str):
        """æ¸…é™¤æœƒè©±è¨˜æ†¶"""
        if session_id in self.sessions:
            del self.sessions[session_id]

    def list_sessions(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰æœƒè©±ID"""
        return list(self.sessions.keys())



# Pydantic æ¨¡å‹


class FlowiseRequest(BaseModel):
    """Flowise æŸ¥è©¢è«‹æ±‚æ¨¡å‹"""
    question: str
    chatId: str

class NewChatRequest(BaseModel):
    """æ–°çš„èŠå¤©è«‹æ±‚æ¨¡å‹"""
    user_query: str
    streaming: bool = False
    sessionId: str

class FlowiseResponse(BaseModel):
    """Flowise æŸ¥è©¢å›æ‡‰æ¨¡å‹"""
    text: str
    question: str
    chatId: str
    sessionId: str
    chatMessageId: str

class NewChatResponse(BaseModel):
    """æ–°çš„èŠå¤©å›æ‡‰æ¨¡å‹"""
    text: str
    user_query: str
    sessionId: str
    chatMessageId: str
    streaming: bool = False

class ImageInfo(BaseModel):
    """åœ–ç‰‡è³‡è¨Šæ¨¡å‹"""
    has_images: bool
    image_url: Optional[str] = None
    image_analysis: Optional[str] = None
    technical_symbols: List[str] = []

class SourceInfo(BaseModel):
    """ä¾†æºè³‡è¨Šæ¨¡å‹"""
    page_num: int
    topic: str
    sub_topic: str
    content: str
    content_type: str
    keywords: List[str]
    similarity_score: float
    relevance_reason: str
    image_info: ImageInfo



class HealthResponse(BaseModel):
    """å¥åº·æª¢æŸ¥å›æ‡‰æ¨¡å‹"""
    status: str
    qdrant_connected: bool
    chunks_loaded: int
    images_available: int

class ProcessPDFResponse(BaseModel):
    """PDFè™•ç†å›æ‡‰æ¨¡å‹"""
    success: bool
    message: str
    chunks_processed: int
    images_extracted: int
    collection_name: str
    processing_time: Optional[float] = None
    errors: List[str] = []

class ChatRequest(BaseModel):
    """èŠå¤©è«‹æ±‚æ¨¡å‹"""
    message: str
    session_id: Optional[str] = None
    use_rag: bool = True
    top_k: int = 3

class TestFolderRequest(BaseModel):
    """è³‡æ–™å¤¾æ¸¬è©¦è«‹æ±‚æ¨¡å‹"""
    folder_name: str
    num_images_per_category: int = 1

class TestResult(BaseModel):
    """æ¸¬è©¦çµæœæ¨¡å‹"""
    image_name: str
    category: str
    question: str
    rag_answer: str
    evaluation: Dict[str, Any]
    cost_info: Dict[str, float]

class TestResponse(BaseModel):
    """æ¸¬è©¦å›æ‡‰æ¨¡å‹"""
    test_id: str
    total_tests: int
    results: List[TestResult]
    summary: Dict[str, Any]
    html_report_url: str

class ChatResponse(BaseModel):
    """èŠå¤©å›æ‡‰æ¨¡å‹"""
    response: str
    session_id: str
    message_count: int
    total_tokens: int
    sources: List[SourceInfo] = []
    rag_used: bool = False

class SessionInfo(BaseModel):
    """æœƒè©±è³‡è¨Šæ¨¡å‹"""
    session_id: str
    exists: bool
    message_count: int = 0
    total_tokens: int = 0

class CollectionInfo(BaseModel):
    """é›†åˆè³‡è¨Šæ¨¡å‹"""
    collection_name: str
    vectors_count: int
    points_count: int
    status: str
    exists: bool

class CollectionCountResponse(BaseModel):
    """é›†åˆæ•¸é‡æª¢æŸ¥å›æ‡‰æ¨¡å‹"""
    success: bool
    collection_info: Optional[CollectionInfo] = None
    error_message: Optional[str] = None
    last_activity: Optional[float] = None



def get_image_url(image_path: str) -> Optional[str]:
    """ç”Ÿæˆåœ–ç‰‡çš„å®Œæ•´ URL - ä½¿ç”¨å¾Œç«¯APIè·¯å¾‘"""
    if not image_path:
        return None

    # æå–æª”æ¡ˆåç¨±ï¼Œè™•ç†å¯èƒ½çš„è·¯å¾‘åˆ†éš”ç¬¦å•é¡Œ
    filename = os.path.basename(image_path.replace('\\', '/'))

    # å¾é…ç½®æ–‡ä»¶è®€å– API åŸºç¤ URL
    api_base_url = f"{Config.API_BASE_URL}/api/v1/JH"

    # æª”æ¡ˆåç¨±éœ€è¦ URL ç·¨ç¢¼ï¼ˆå› ç‚ºåŒ…å«ä¸­æ–‡ï¼‰
    from urllib.parse import quote
    encoded_filename = quote(filename)

    # ç”Ÿæˆå¾Œç«¯ API URL
    image_url = f"{api_base_url}/images/{encoded_filename}"

    return image_url

def format_answer_with_images(answer: str) -> str:
    """å°‡å›ç­”ä¸­çš„åœ–ç‰‡ URL è½‰æ›ç‚ºå¯¦éš›çš„åœ–ç‰‡é¡¯ç¤º"""
    import re

    # å…ˆè™•ç† "ğŸ“· ç›¸é—œåœ–ç‰‡ï¼š" éƒ¨åˆ†çš„ç·¨è™ŸURL
    if "ğŸ“· ç›¸é—œåœ–ç‰‡" in answer:
        # æ”¶é›†ç·¨è™Ÿçš„åœ–ç‰‡URL
        numbered_url_pattern = r'\d+\.\s*(https?://[^\s]+\.(?:png|jpg|jpeg|gif|bmp))'
        urls = re.findall(numbered_url_pattern, answer)

        if urls:
            # ç§»é™¤æ•´å€‹ç·¨è™ŸURLè¡Œ
            answer = re.sub(r'\d+\.\s*https?://[^\s]+\.(?:png|jpg|jpeg|gif|bmp)', '', answer)

            # å‰µå»ºä¸¦æ’çš„åœ–ç‰‡å®¹å™¨ - é©ä¸­å¤§å°ï¼Œç¢ºä¿å®Œæ•´é¡¯ç¤º
            images_html = '<div style="display: flex; flex-direction: row; flex-wrap: wrap; gap: 20px; margin: 20px 0; justify-content: center; align-items: flex-start;">'
            for url in urls:
                images_html += f'''
                <div style="flex: 1; max-width: 400px; min-width: 300px; text-align: center;">
                    <img src="{url}" alt="ç›¸é—œåœ–ç‰‡"
                         style="width: 100%; max-width: 400px; height: auto; border: 2px solid #2c3e50; border-radius: 8px;
                                box-shadow: 0 4px 12px rgba(0,0,0,0.15); cursor: pointer; transition: transform 0.2s;
                                object-fit: contain;"
                         onclick="window.open('{url}', '_blank')"
                         onmouseover="this.style.transform='scale(1.05)'; this.style.boxShadow='0 6px 20px rgba(52, 152, 219, 0.3)'"
                         onmouseout="this.style.transform='scale(1)'; this.style.boxShadow='0 4px 12px rgba(0,0,0,0.15)'">
                </div>'''
            images_html += '</div>'

            # æ›¿æ›åˆ°åŸä½ç½®
            answer = answer.replace('ğŸ“· ç›¸é—œåœ–ç‰‡ï¼š', f'ğŸ“· ç›¸é—œåœ–ç‰‡ï¼š{images_html}')

            # ç›´æ¥è¿”å›ï¼Œä¸å†è™•ç†å…¶ä»–URLï¼ˆé¿å…é‡è¤‡è™•ç†ï¼‰
            return answer

    # è™•ç†å…¶ä»–å–®ç¨çš„åœ–ç‰‡URLï¼ˆåªæœ‰åœ¨æ²’æœ‰ç›¸é—œåœ–ç‰‡å€å¡Šæ™‚æ‰åŸ·è¡Œï¼‰
    url_pattern = r'https?://[^\s]+\.(?:png|jpg|jpeg|gif|bmp)'
    def replace_url_with_img(match):
        url = match.group(0)
        return f'<br><img src="{url}" alt="ç›¸é—œåœ–ç‰‡" style="width: 100%; max-width: 600px; height: auto; margin: 15px 0; border: 2px solid #2c3e50; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.15); cursor: pointer; object-fit: contain;" onclick="window.open(\'{url}\', \'_blank\')">'

    # æ›¿æ›å‰©é¤˜çš„ URL ç‚ºåœ–ç‰‡æ¨™ç±¤
    formatted_answer = re.sub(url_pattern, replace_url_with_img, answer)

    return formatted_answer

async def stream_chat_response(request: NewChatRequest):
    """ä¸²æµèŠå¤©å›æ‡‰ç”Ÿæˆå™¨"""
    try:
        import uuid
        from openai import OpenAI

        logger.info(f"é–‹å§‹ä¸²æµå›æ‡‰: {request.user_query} (sessionId: {request.sessionId})")

        # ä½¿ç”¨ sessionId ä½œç‚º session_id
        session_id = request.sessionId

        # ç²å–æœƒè©±è¨˜æ†¶
        messages = memory_manager.get_session(session_id)

        # æ·»åŠ ç”¨æˆ¶è¨Šæ¯åˆ°è¨˜æ†¶
        memory_manager.add_message(session_id, "user", request.user_query)

        # æº–å‚™å›æ‡‰å…§å®¹
        sources = []
        rag_used = False
        image_urls = []
        rag_message = None

        # æª¢ç´¢ç›¸é—œå…§å®¹ (é è¨­å•Ÿç”¨RAG)
        # æª¢æŸ¥ Qdrant é›†åˆæ˜¯å¦æœ‰è³‡æ–™ï¼Œè€Œä¸æ˜¯æª¢æŸ¥æœ¬åœ° chunks
        if rag_system.has_vector_data():
            try:
                # æª¢ç´¢ç›¸é—œæ–‡ä»¶æ®µè½ - å¢åŠ æª¢ç´¢æ•¸é‡ä»¥ç¢ºä¿æœ‰è¶³å¤ åœ–ç‰‡
                retrieval_results = rag_system.retrieve_relevant_chunks(
                    query=request.user_query,
                    top_k=10  # å¢åŠ æª¢ç´¢æ•¸é‡ä»¥ç¢ºä¿æœ‰è¶³å¤ åœ–ç‰‡
                )

                if retrieval_results:
                    rag_used = True

                    # æº–å‚™RAGä¸Šä¸‹æ–‡
                    rag_context_parts = []
                    for result in retrieval_results:
                        context_part = f"ã€{result.parent_chunk.topic}ã€‘\n{result.parent_chunk.content}"

                        # æ·»åŠ ç›¸é—œåœ–ç‰‡
                        if result.parent_chunk.has_images and result.parent_chunk.image_paths:
                            current_image_urls = []
                            for image_path in result.parent_chunk.image_paths:
                                # ä½¿ç”¨çµ±ä¸€çš„ URL ç”Ÿæˆå‡½æ•¸
                                image_url = get_image_url(image_path)
                                if image_url:
                                    current_image_urls.append(image_url)
                                    # æ·»åŠ åˆ°å…¨å±€åœ–ç‰‡URLåˆ—è¡¨ï¼ˆæœ€å¤š3å¼µï¼‰
                                    if image_url not in image_urls and len(image_urls) < 3:
                                        image_urls.append(image_url)

                            if current_image_urls:
                                context_part += f"\n\nç›¸é—œåœ–ç‰‡ï¼š\n" + "\n".join(current_image_urls)

                        rag_context_parts.append(context_part)

                    rag_context = "\n\n".join(rag_context_parts)

                    # æ·»åŠ RAGä¸Šä¸‹æ–‡åˆ°å°è©±
                    rag_message = f"""åŸºæ–¼ä»¥ä¸‹æ•™æå…§å®¹å›ç­”å•é¡Œï¼š

{rag_context}

ç”¨æˆ¶å•é¡Œï¼š{request.user_query}

è«‹çµåˆæ•™æå…§å®¹å’Œå°è©±æ­·å²ï¼Œç”¨æ¸…æ¥šå‹å–„çš„æ–¹å¼å›ç­”å•é¡Œã€‚å¦‚æœæ•™æä¸­æœ‰ç›¸é—œåœ–ç‰‡ï¼Œè«‹åœ¨å›ç­”ä¸­æåŠã€‚"""

                    # æ”¶é›†åœ–ç‰‡ URL (å·²åœ¨ä¸Šé¢çš„å¾ªç’°ä¸­è™•ç†)

            except Exception as e:
                logger.error(f"RAGæª¢ç´¢å¤±æ•—: {e}")
                rag_used = False

        # æº–å‚™å°è©±è¨Šæ¯
        temp_messages = messages.copy()
        if rag_used and rag_message:
            temp_messages.append({"role": "user", "content": rag_message})
        else:
            # å¦‚æœæ²’æœ‰RAGå…§å®¹ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹å•é¡Œ
            temp_messages.append({"role": "user", "content": request.user_query})

        # èª¿ç”¨OpenAI APIç”Ÿæˆä¸²æµå›æ‡‰
        client = OpenAI(api_key=Config.OPENAI_API_KEY)

        stream = client.chat.completions.create(
            model=Config.OPENAI_MODEL,
            messages=temp_messages,
            max_tokens=Config.MAX_TOKENS,
            temperature=Config.TEMPERATURE,
            stream=True
        )

        # æ”¶é›†å®Œæ•´å›æ‡‰ç”¨æ–¼è¨˜æ†¶å„²å­˜
        full_response = ""

        # ä¸²æµè¼¸å‡º
        for chunk in stream:
            if chunk.choices[0].delta.content is not None:
                content = chunk.choices[0].delta.content
                full_response += content
                yield f"data: {json.dumps({'content': content, 'type': 'text'}, ensure_ascii=False)}\n\n"

        # æ·»åŠ åœ–ç‰‡ URL
        if image_urls:
            full_response += "\n\nğŸ“· ç›¸é—œåœ–ç‰‡ï¼š"
            for i, url in enumerate(image_urls, 1):
                full_response += f"\n{i}. {url}"
                newline_content = f'\n{i}. {url}'
                yield f"data: {json.dumps({'content': newline_content, 'type': 'image_url'}, ensure_ascii=False)}\n\n"

        # ç™¼é€å®Œæˆä¿¡è™Ÿ
        message_id = str(uuid.uuid4())
        yield f"data: {json.dumps({'type': 'done', 'sessionId': session_id, 'chatMessageId': message_id}, ensure_ascii=False)}\n\n"

        # æ·»åŠ åŠ©æ‰‹å›æ‡‰åˆ°è¨˜æ†¶
        memory_manager.add_message(session_id, "assistant", full_response)

        logger.info(f"ä¸²æµå›æ‡‰å®Œæˆ - æœƒè©±: {session_id}, RAG: {rag_used}")

    except Exception as e:
        logger.error(f"ä¸²æµå›æ‡‰å¤±æ•—: {e}")
        yield f"data: {json.dumps({'error': f'ä¸²æµå›æ‡‰å¤±æ•—: {str(e)}'}, ensure_ascii=False)}\n\n"

@app.get("/", response_model=Dict[str, str])
async def root():
    """æ ¹è·¯å¾‘ - API è³‡è¨Š"""
    return {
        "message": "åœ–é¢è­˜åˆ¥æ•™å­¸ RAG API",
        "version": "1.0.0",
        "docs": "/docs",
        "health": "/health"
    }

@app.get("/current-collection")
async def get_current_collection():
    """ç²å–ç•¶å‰ä½¿ç”¨çš„ Qdrant é›†åˆè³‡è¨Š"""
    try:
        if rag_system is None:
            raise HTTPException(status_code=500, detail="RAGç³»çµ±æœªåˆå§‹åŒ–")

        collection_info = rag_system.get_collection_info()

        return {
            "current_collection": rag_system.collection_name,
            "qdrant_url": rag_system.qdrant_url,
            "collection_info": collection_info,
            "has_vector_data": rag_system.has_vector_data()
        }
    except Exception as e:
        logger.error(f"ç²å–ç•¶å‰é›†åˆè³‡è¨Šå¤±æ•—: {e}")
        return {
            "current_collection": rag_system.collection_name if rag_system else "æœªçŸ¥",
            "qdrant_url": rag_system.qdrant_url if rag_system else "æœªçŸ¥",
            "error": str(e)
        }

@app.get("/images/{filename}")
@app.head("/images/{filename}")
@app.options("/images/{filename}")
async def serve_image(filename: str):
    """æ‰‹å‹•æä¾›åœ–ç‰‡æª”æ¡ˆ"""
    try:
        from fastapi.responses import FileResponse
        from urllib.parse import unquote

        # URLè§£ç¢¼æª”æ¡ˆåç¨±
        decoded_filename = unquote(filename)
        logger.info(f"è«‹æ±‚çš„æª”æ¡ˆåç¨±: {filename}")
        logger.info(f"è§£ç¢¼å¾Œçš„æª”æ¡ˆåç¨±: {decoded_filename}")

        # è™•ç†å¯èƒ½çš„è·¯å¾‘å•é¡Œ
        # å¦‚æœæª”æ¡ˆåç¨±åŒ…å«è·¯å¾‘åˆ†éš”ç¬¦ï¼Œåªå–æª”æ¡ˆåç¨±éƒ¨åˆ†
        clean_filename = os.path.basename(decoded_filename.replace('\\', '/'))
        file_path = os.path.join(IMAGES_DIR, clean_filename)

        logger.info(f"æ¸…ç†å¾Œçš„æª”æ¡ˆåç¨±: {clean_filename}")
        logger.info(f"å®Œæ•´æª”æ¡ˆè·¯å¾‘: {file_path}")

        # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
        if not os.path.exists(file_path):
            # åˆ—å‡ºIMAGES_DIRç›®éŒ„ä¸­çš„ç›¸ä¼¼æª”æ¡ˆ
            similar_files = []
            if os.path.exists(IMAGES_DIR):
                for f in os.listdir(IMAGES_DIR):
                    if clean_filename.lower() in f.lower() or f.lower() in clean_filename.lower():
                        similar_files.append(f)

            logger.warning(f"åœ–ç‰‡æª”æ¡ˆä¸å­˜åœ¨: {file_path}")
            logger.warning(f"ç›¸ä¼¼æª”æ¡ˆ: {similar_files}")
            raise HTTPException(
                status_code=404,
                detail=f"åœ–ç‰‡æª”æ¡ˆä¸å­˜åœ¨: {clean_filename}. ç›¸ä¼¼æª”æ¡ˆ: {similar_files[:3]}"
            )

        # æª¢æŸ¥æ˜¯å¦ç‚ºåœ–ç‰‡æª”æ¡ˆ
        if not clean_filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):
            raise HTTPException(status_code=400, detail="ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼")

        logger.info(f"æˆåŠŸæä¾›åœ–ç‰‡æª”æ¡ˆ: {file_path}")

        # å‰µå»ºFileResponseä¸¦æ·»åŠ CORSæ¨™é ­
        response = FileResponse(
            file_path,
            headers={
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Allow-Methods": "GET, HEAD, OPTIONS",
                "Access-Control-Allow-Headers": "*",
                "Cache-Control": "public, max-age=3600"
            }
        )
        return response

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æä¾›åœ–ç‰‡æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        raise HTTPException(status_code=500, detail="å…§éƒ¨ä¼ºæœå™¨éŒ¯èª¤")

@app.get("/debug/images")
async def debug_images():
    """èª¿è©¦åœ–ç‰‡æª”æ¡ˆç«¯é»"""
    try:
        if not os.path.exists(IMAGES_DIR):
            return {"error": f"{IMAGES_DIR}ç›®éŒ„ä¸å­˜åœ¨"}

        # åˆ—å‡ºæ‰€æœ‰åœ–ç‰‡æª”æ¡ˆ
        image_files = []
        for file in os.listdir(IMAGES_DIR):
            if file.endswith(('.png', '.jpg', '.jpeg')):
                file_path = os.path.join(IMAGES_DIR, file)
                file_size = os.path.getsize(file_path)
                image_files.append({
                    "filename": file,
                    "size": file_size,
                    "url": f"/images/{file}"
                })

        return {
            "total_images": len(image_files),
            "images": image_files[:10],  # åªé¡¯ç¤ºå‰10å€‹
            "images_directory_exists": True,
            "static_mount_path": "/images"
        }
    except Exception as e:
        return {"error": str(e)}

@app.get("/health", response_model=HealthResponse)
async def health_check():
    """å¥åº·æª¢æŸ¥ç«¯é»"""
    try:
        # æª¢æŸ¥ RAG ç³»çµ±ç‹€æ…‹
        if rag_system is None:
            return HealthResponse(
                status="error",
                qdrant_connected=False,
                chunks_loaded=0,
                images_available=0
            )

        # æª¢æŸ¥ Qdrant é€£ç·š
        qdrant_connected = True
        try:
            # å˜—è©¦ç²å–é›†åˆè³‡è¨Š
            collection_info = rag_system.qdrant_client.get_collection(rag_system.collection_name)
            qdrant_connected = True
        except Exception:
            qdrant_connected = False

        # çµ±è¨ˆåœ–ç‰‡æ•¸é‡
        images_count = 0
        if os.path.exists(IMAGES_DIR):
            images_count = len([f for f in os.listdir(IMAGES_DIR) if f.endswith(('.png', '.jpg', '.jpeg'))])

        # æª¢æŸ¥å‘é‡è³‡æ–™åº«ä¸­çš„è³‡æ–™é‡
        chunks_loaded = 0
        if qdrant_connected and rag_system.has_vector_data():
            try:
                # ç²å–å­æ®µè½é›†åˆçš„è³‡æ–™é‡
                child_info = rag_system.qdrant_client.get_collection(rag_system.child_collection_name)
                chunks_loaded = child_info.vectors_count or child_info.points_count or 0
            except Exception as e:
                logger.warning(f"ç„¡æ³•ç²å–å‘é‡è³‡æ–™é‡: {e}")
                chunks_loaded = 0

        return HealthResponse(
            status="healthy" if qdrant_connected else "degraded",
            qdrant_connected=qdrant_connected,
            chunks_loaded=chunks_loaded,
            images_available=images_count
        )

    except Exception as e:
        logger.error(f"å¥åº·æª¢æŸ¥å¤±æ•—: {e}")
        return HealthResponse(
            status="error",
            qdrant_connected=False,
            chunks_loaded=0,
            images_available=0
        )



@app.post("/query", response_model=FlowiseResponse)
async def query_rag(request: FlowiseRequest):
    """RAG æŸ¥è©¢ç«¯é»"""
    if rag_system is None:
        raise HTTPException(status_code=500, detail="RAG ç³»çµ±æœªåˆå§‹åŒ–")

    try:
        import time
        import uuid

        logger.info(f"æ”¶åˆ°æŸ¥è©¢: {request.question} (chatId: {request.chatId})")

        # ä½¿ç”¨ Parent-Child RAG ç³»çµ±ç”Ÿæˆå›ç­”
        response = rag_system.generate_answer(
            query=request.question,
            top_k=10  # å¢åŠ æª¢ç´¢æ•¸é‡ä»¥ç¢ºä¿æœ‰è¶³å¤ åœ–ç‰‡
        )

        # æ”¶é›†æœ€å¤šä¸‰å¼µåœ–ç‰‡ URL
        image_urls = []
        seen_urls = set()
        for source in response.get("sources", []):
            if source.get("has_images", False) and source.get("image_paths"):
                for image_path in source["image_paths"]:
                    image_url = get_image_url(image_path)
                    if image_url and image_url not in seen_urls:
                        image_urls.append(image_url)
                        seen_urls.add(image_url)
                        if len(image_urls) >= 3:  # æœ€å¤šæ”¶é›†3å¼µåœ–ç‰‡
                            break
            if len(image_urls) >= 3:  # å¦‚æœå·²ç¶“æ”¶é›†åˆ°3å¼µåœ–ç‰‡ï¼Œåœæ­¢æœç´¢
                break

        # æº–å‚™å›æ‡‰ï¼Œå°‡åœ–ç‰‡ URL ä½œç‚ºå–®ç¨å­—æ®µè¿”å›
        answer = response["answer"]

        # å¯é¸ï¼šä»ç„¶åœ¨æ–‡æœ¬ä¸­æ·»åŠ åœ–ç‰‡ URL ä»¥ä¿æŒå‘å¾Œå…¼å®¹
        if image_urls:
            answer += "\n\nğŸ“· ç›¸é—œåœ–ç‰‡ï¼š"
            for i, url in enumerate(image_urls, 1):
                answer += f"\n{i}. {url}"

        # ç”Ÿæˆå”¯ä¸€çš„ sessionId å’Œ chatMessageId
        session_id = f"session_{request.chatId}_{int(time.time())}"
        chat_message_id = str(uuid.uuid4())

        return FlowiseResponse(
            text=answer,  # åªè¿”å›ç´”æ–‡å­—ï¼Œä¸é€²è¡ŒHTMLè½‰æ›
            question=request.question,
            chatId=request.chatId,
            sessionId=session_id,
            chatMessageId=chat_message_id
        )

    except Exception as e:
        logger.error(f"æŸ¥è©¢è™•ç†å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"æŸ¥è©¢è™•ç†å¤±æ•—: {str(e)}")

@app.post("/query-with-memory")
async def query_flowise_with_memory(request: NewChatRequest):
    """
    æ–°æ ¼å¼çš„è¨˜æ†¶å°è©±API

    æ¥æ”¶æ–°æ ¼å¼çš„è«‹æ±‚ï¼Œä½¿ç”¨è¨˜æ†¶å°è©±åŠŸèƒ½
    - **user_query**: ç”¨æˆ¶å•é¡Œ
    - **sessionId**: èŠå¤©æœƒè©±ID
    - **streaming**: æ˜¯å¦ä½¿ç”¨ä¸²æµæ¨¡å¼

    å…·æœ‰å®Œæ•´çš„æœƒè©±è¨˜æ†¶åŠŸèƒ½ï¼Œæ”¯æ´RAGæª¢ç´¢
    """
    if rag_system is None:
        raise HTTPException(status_code=500, detail="RAGç³»çµ±æœªåˆå§‹åŒ–")

    # å¦‚æœå•Ÿç”¨ streamingï¼Œè¿”å› StreamingResponse
    if request.streaming:
        return StreamingResponse(
            stream_chat_response(request),
            media_type="text/plain",
            headers={"Cache-Control": "no-cache", "Connection": "keep-alive"}
        )

    try:
        import uuid

        logger.info(f"æ”¶åˆ°è¨˜æ†¶å°è©±æŸ¥è©¢: {request.user_query} (sessionId: {request.sessionId})")

        # ä½¿ç”¨ sessionId ä½œç‚º session_id
        session_id = request.sessionId

        # ç²å–æœƒè©±è¨˜æ†¶
        messages = memory_manager.get_session(session_id)

        # æ·»åŠ ç”¨æˆ¶è¨Šæ¯åˆ°è¨˜æ†¶
        memory_manager.add_message(session_id, "user", request.user_query)

        # æº–å‚™å›æ‡‰å…§å®¹
        response_content = ""
        sources = []
        rag_used = False
        image_urls = []

        # æª¢ç´¢ç›¸é—œå…§å®¹ (é è¨­å•Ÿç”¨RAG)
        if rag_system.has_vector_data():
            try:
                # æª¢ç´¢ç›¸é—œæ–‡ä»¶æ®µè½
                retrieval_results = rag_system.retrieve_relevant_chunks(
                    query=request.user_query,
                    top_k=3  # é è¨­ä½¿ç”¨3å€‹ç›¸é—œæ–‡ä»¶
                )

                if retrieval_results:
                    rag_used = True

                    # æº–å‚™RAGä¸Šä¸‹æ–‡
                    rag_context_parts = []
                    for result in retrieval_results:
                        context_part = f"ã€{result.parent_chunk.topic}ã€‘\n{result.parent_chunk.content}"

                        # æ·»åŠ ç›¸é—œåœ–ç‰‡
                        if result.parent_chunk.has_images and result.parent_chunk.image_paths:
                            current_image_urls = []
                            for image_path in result.parent_chunk.image_paths:
                                # ä½¿ç”¨çµ±ä¸€çš„ URL ç”Ÿæˆå‡½æ•¸
                                image_url = get_image_url(image_path)
                                if image_url:
                                    current_image_urls.append(image_url)
                                    # æ·»åŠ åˆ°å…¨å±€åœ–ç‰‡URLåˆ—è¡¨ï¼ˆæœ€å¤š3å¼µï¼‰
                                    if image_url not in image_urls and len(image_urls) < 3:
                                        image_urls.append(image_url)

                            if current_image_urls:
                                context_part += f"\n\nç›¸é—œåœ–ç‰‡ï¼š\n" + "\n".join(current_image_urls)

                        rag_context_parts.append(context_part)

                    rag_context = "\n\n".join(rag_context_parts)

                    # æ·»åŠ RAGä¸Šä¸‹æ–‡åˆ°å°è©±
                    rag_message = f"""åŸºæ–¼ä»¥ä¸‹æ•™æå…§å®¹å›ç­”å•é¡Œï¼š

{rag_context}

ç”¨æˆ¶å•é¡Œï¼š{request.user_query}

è«‹çµåˆæ•™æå…§å®¹å’Œå°è©±æ­·å²ï¼Œç”¨æ¸…æ¥šå‹å–„çš„æ–¹å¼å›ç­”å•é¡Œã€‚å¦‚æœæ•™æä¸­æœ‰ç›¸é—œåœ–ç‰‡ï¼Œè«‹åœ¨å›ç­”ä¸­æåŠã€‚"""

                    # æº–å‚™ä¾†æºè³‡è¨Š
                    for result in retrieval_results:
                        # ä½¿ç”¨çˆ¶æ®µè½ä½œç‚ºä¸»è¦å…§å®¹ä¾†æº
                        parent_chunk = result.parent_chunk
                        child_chunk = result.child_chunk

                        # å®‰å…¨åœ°å­˜å–è¦–è¦ºç›¸é—œå±¬æ€§ï¼ˆå¾çˆ¶æ®µè½ï¼‰
                        has_images = hasattr(parent_chunk, 'has_images') and getattr(parent_chunk, 'has_images', False)
                        image_paths = getattr(parent_chunk, 'image_paths', []) if has_images else []
                        image_analyses = getattr(parent_chunk, 'image_analyses', []) if has_images else []

                        # å¾å­æ®µè½ç²å–æŠ€è¡“ç¬¦è™Ÿï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
                        technical_symbols = getattr(child_chunk, 'technical_symbols', []) if hasattr(child_chunk, 'technical_symbols') else []

                        # èª¿è©¦æ—¥èªŒ
                        logger.info(f"æª¢ç´¢çµæœèª¿è©¦ - é é¢ç¯„åœ: {parent_chunk.page_range}, has_images: {has_images}, image_paths: {image_paths}")

                        # è™•ç†åœ–ç‰‡è³‡è¨Š
                        image_url = None
                        image_analysis = ""
                        if has_images and image_paths:
                            # ä½¿ç”¨ç¬¬ä¸€å€‹åœ–ç‰‡è·¯å¾‘
                            first_image_path = image_paths[0]
                            image_url = get_image_url(first_image_path) if first_image_path else None
                            # ä½¿ç”¨ç¬¬ä¸€å€‹åœ–ç‰‡åˆ†æ
                            image_analysis = image_analyses[0] if image_analyses else ""

                        image_info = ImageInfo(
                            has_images=has_images,
                            image_url=image_url,
                            image_analysis=image_analysis,
                            technical_symbols=technical_symbols
                        )

                        sources.append(SourceInfo(
                            page_num=child_chunk.page_num,
                            topic=parent_chunk.topic,
                            sub_topic=child_chunk.sub_topic,
                            content=child_chunk.content[:200] + "..." if len(child_chunk.content) > 200 else child_chunk.content,
                            content_type=child_chunk.content_type,
                            keywords=child_chunk.keywords or [],
                            similarity_score=result.similarity_score,
                            relevance_reason=f"èˆ‡å•é¡Œç›¸é—œåº¦: {result.similarity_score:.3f}",
                            image_info=image_info
                        ))

            except Exception as e:
                logger.warning(f"RAGæª¢ç´¢å¤±æ•—: {e}")

        # æº–å‚™ç™¼é€çµ¦OpenAIçš„è¨Šæ¯
        temp_messages = messages.copy()
        if rag_used:
            temp_messages.append({"role": "user", "content": rag_message})
        else:
            # å¦‚æœæ²’æœ‰RAGå…§å®¹ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹å•é¡Œ
            temp_messages.append({"role": "user", "content": request.user_query})

        # èª¿ç”¨OpenAI APIç”Ÿæˆå›æ‡‰
        from openai import OpenAI
        client = OpenAI(api_key=Config.OPENAI_API_KEY)

        completion = client.chat.completions.create(
            model=Config.OPENAI_MODEL,
            messages=temp_messages,
            max_tokens=Config.MAX_TOKENS,
            temperature=Config.TEMPERATURE
        )

        response_content = completion.choices[0].message.content

        # æ³¨æ„ï¼šimage_urls å·²ç¶“åœ¨ä¸Šé¢çš„æª¢ç´¢éç¨‹ä¸­æ”¶é›†äº†ï¼Œé€™è£¡ä¸éœ€è¦é‡æ–°å®šç¾©
        # å¦‚æœä¸Šé¢æ²’æœ‰æ”¶é›†åˆ°åœ–ç‰‡ï¼Œå†å¾ sources ä¸­æ”¶é›†
        if not image_urls:
            for source in sources:
                if source.image_info.has_images and source.image_info.image_url:
                    if source.image_info.image_url not in image_urls and len(image_urls) < 3:
                        image_urls.append(source.image_info.image_url)

        # åœ¨å›ç­”å¾Œé¢æ·»åŠ åœ–ç‰‡ URL (ä¿æŒèˆ‡åŸå§‹ /query ç«¯é»ä¸€è‡´çš„æ ¼å¼)
        if image_urls:
            response_content += "\n\nğŸ“· ç›¸é—œåœ–ç‰‡ï¼š"
            for i, url in enumerate(image_urls, 1):
                response_content += f"\n{i}. {url}"

        # æ·»åŠ åŠ©æ‰‹å›æ‡‰åˆ°è¨˜æ†¶ï¼ˆä¿å­˜åŸå§‹æ–‡æœ¬ï¼‰
        memory_manager.add_message(session_id, "assistant", response_content)

        # ç”Ÿæˆå›æ‡‰ID
        message_id = str(uuid.uuid4())

        # ç²å–æœƒè©±çµ±è¨ˆ
        session_summary = memory_manager.get_session_summary(session_id)

        logger.info(f"è¨˜æ†¶å°è©±å®Œæˆ - æœƒè©±: {session_id}, RAG: {rag_used}, è¨Šæ¯æ•¸: {session_summary['message_count']}")

        # å°æ–¼éä¸²æµæ¨¡å¼ï¼Œå›å‚³ç°¡åŒ–çš„ JSON æ ¼å¼ï¼ˆåªè¿”å›ç´”æ–‡å­—ï¼Œä¸é€²è¡ŒHTMLè½‰æ›ï¼‰
        return {"reply": response_content}

    except Exception as e:
        logger.error(f"è¨˜æ†¶å°è©±è™•ç†å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"è¨˜æ†¶å°è©±è™•ç†å¤±æ•—: {str(e)}")






@app.post("/process-file", response_model=ProcessPDFResponse)
async def process_file(
    file: UploadFile = File(..., description="æ”¯æ´çš„æ–‡ä»¶æ ¼å¼ï¼šPDFã€Excel(.xlsx/.xls)ã€Word(.docx/.doc)ã€PowerPoint(.pptx/.ppt)"),
    collection_name: Optional[str] = Query(None, description="è‡ªå®šç¾©é›†åˆåç¨±ï¼Œå¦‚ä¸æä¾›å‰‡ä½¿ç”¨é è¨­"),
    enable_vision: bool = Query(True, description="æ˜¯å¦å•Ÿç”¨è¦–è¦ºåˆ†æ"),
    force_recreate: bool = Query(False, description="æ˜¯å¦å¼·åˆ¶é‡æ–°å‰µå»ºé›†åˆ")
):
    """
    è™•ç†ä¸Šå‚³çš„å¤šæ ¼å¼æ–‡ä»¶ä¸¦è‡ªå‹•embeddingåˆ°Qdrant

    æ”¯æ´çš„æ ¼å¼ï¼š
    - PDF (.pdf) - ç›´æ¥è™•ç†
    - Excel (.xlsx, .xls) - è‡ªå‹•è½‰æ›ç‚ºPDFå¾Œè™•ç†
    - Word (.docx, .doc) - è‡ªå‹•è½‰æ›ç‚ºPDFå¾Œè™•ç†
    - PowerPoint (.pptx, .ppt) - è‡ªå‹•è½‰æ›ç‚ºPDFå¾Œè™•ç†

    - **file**: è¦è™•ç†çš„æ–‡ä»¶
    - **collection_name**: å¯é¸çš„è‡ªå®šç¾©é›†åˆåç¨±
    - **enable_vision**: æ˜¯å¦å•Ÿç”¨GPT-4oè¦–è¦ºåˆ†æ
    - **force_recreate**: æ˜¯å¦å¼·åˆ¶é‡æ–°å‰µå»ºå‘é‡é›†åˆ
    """
    import time
    start_time = time.time()
    errors = []

    # åˆå§‹åŒ–æª”æ¡ˆè½‰æ›å™¨
    file_converter = FileConverter()

    # æª¢æŸ¥æ–‡ä»¶é¡å‹
    if not file_converter.is_supported_format(file.filename):
        supported_formats = list(file_converter.supported_formats.keys())
        raise HTTPException(
            status_code=400,
            detail=f"ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼ã€‚æ”¯æ´çš„æ ¼å¼: {', '.join(supported_formats)}"
        )

    try:
        # ç²å–æª”æ¡ˆå‰¯æª”å
        file_ext = Path(file.filename).suffix.lower()

        # å‰µå»ºè‡¨æ™‚æ–‡ä»¶ä¾†å„²å­˜ä¸Šå‚³çš„æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as temp_file:
            # å°‡ä¸Šå‚³çš„æ–‡ä»¶å…§å®¹å¯«å…¥è‡¨æ™‚æ–‡ä»¶
            shutil.copyfileobj(file.file, temp_file)
            temp_input_path = temp_file.name

        logger.info(f"é–‹å§‹è™•ç†æ–‡ä»¶: {file.filename} (æ ¼å¼: {file_ext})")

        # å¦‚æœä¸æ˜¯PDFï¼Œå…ˆè½‰æ›ç‚ºPDF
        if file_ext != '.pdf':
            logger.info(f"æ­£åœ¨å°‡ {file_ext} æ ¼å¼è½‰æ›ç‚ºPDF...")
            temp_pdf_path = temp_input_path.replace(file_ext, '.pdf')

            # åŸ·è¡Œæ ¼å¼è½‰æ›
            converted_pdf = file_converter.convert_to_pdf(temp_input_path, temp_pdf_path)
            if not converted_pdf:
                raise HTTPException(
                    status_code=500,
                    detail=f"æª”æ¡ˆæ ¼å¼è½‰æ›å¤±æ•—ï¼šç„¡æ³•å°‡ {file_ext} è½‰æ›ç‚ºPDF"
                )
            logger.info(f"æ ¼å¼è½‰æ›æˆåŠŸ: {converted_pdf}")
        else:
            # å¦‚æœå·²ç¶“æ˜¯PDFï¼Œç›´æ¥ä½¿ç”¨
            temp_pdf_path = temp_input_path

        # åˆå§‹åŒ–PDFè™•ç†å™¨
        pdf_processor = PDFProcessor(enable_vision_analysis=enable_vision)

        # è™•ç†PDFæ–‡ä»¶
        chunks = pdf_processor.process_pdf(
            pdf_path=temp_pdf_path,
            output_path="temp_processed_chunks.jsonl"
        )

        if not chunks:
            raise HTTPException(status_code=400, detail="PDFè™•ç†å¤±æ•—ï¼Œæœªèƒ½æå–åˆ°ä»»ä½•å…§å®¹")

        # çµ±è¨ˆåœ–ç‰‡æ•¸é‡
        images_count = len([c for c in chunks if hasattr(c, 'has_images') and c.has_images])

        # åˆå§‹åŒ– RAG ç³»çµ±
        target_collection = collection_name or f"pdf_{int(time.time())}"
        rag_system_temp = LangChainParentChildRAG(target_collection)
        logger.info("ä½¿ç”¨ LangChain Parent-Child ç­–ç•¥è™•ç†æ®µè½...")
        result = rag_system_temp.add_documents_from_zerox(chunks)

        if not result["success"]:
            raise HTTPException(status_code=500, detail="Parent-Child è™•ç†å¤±æ•—")

        # æ›´æ–°å…¨åŸŸRAGç³»çµ±ï¼ˆå¦‚æœä½¿ç”¨é è¨­é›†åˆåç¨±ï¼‰
        global rag_system
        if target_collection == rag_system.collection_name:
            # é‡æ–°åˆå§‹åŒ–å…¨åŸŸ RAG ç³»çµ±ä»¥è¼‰å…¥æ–°æ•¸æ“š
            rag_system = LangChainParentChildRAG(target_collection)
            logger.info("å·²æ›´æ–°å…¨åŸŸ LangChain RAG ç³»çµ±")

        processing_time = time.time() - start_time

        # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
        try:
            # æ¸…ç†åŸå§‹ä¸Šå‚³æ–‡ä»¶
            if os.path.exists(temp_input_path):
                os.unlink(temp_input_path)
            # æ¸…ç†è½‰æ›å¾Œçš„PDFï¼ˆå¦‚æœä¸åŒæ–¼åŸå§‹æ–‡ä»¶ï¼‰
            if temp_pdf_path != temp_input_path and os.path.exists(temp_pdf_path):
                os.unlink(temp_pdf_path)
            # æ¸…ç†è™•ç†éç¨‹ä¸­çš„è‡¨æ™‚æ–‡ä»¶
            if os.path.exists("temp_processed_chunks.jsonl"):
                os.unlink("temp_processed_chunks.jsonl")
        except Exception as e:
            errors.append(f"æ¸…ç†è‡¨æ™‚æ–‡ä»¶å¤±æ•—: {str(e)}")

        logger.info(f"æ–‡ä»¶è™•ç†å®Œæˆï¼ŒåŸå§‹æ®µè½: {len(chunks)}ï¼Œçˆ¶æ®µè½: {result['parent_chunks']}ï¼Œå­æ®µè½: {result['child_chunks']}ï¼Œè€—æ™‚ {processing_time:.2f} ç§’")

        return ProcessPDFResponse(
            success=True,
            message=f"æˆåŠŸè™•ç†æ–‡ä»¶ '{file.filename}' ({file_ext} -> PDF) - Parent-Childç­–ç•¥",
            chunks_processed=result['child_chunks'],  # å ±å‘Šå­æ®µè½æ•¸é‡
            images_extracted=images_count,
            collection_name=target_collection,
            processing_time=processing_time,
            errors=errors
        )

    except HTTPException:
        # é‡æ–°æ‹‹å‡ºHTTPç•°å¸¸
        raise
    except Exception as e:
        logger.error(f"æ–‡ä»¶è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")

        # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
        try:
            if 'temp_input_path' in locals() and os.path.exists(temp_input_path):
                os.unlink(temp_input_path)
            if 'temp_pdf_path' in locals() and os.path.exists(temp_pdf_path):
                os.unlink(temp_pdf_path)
            if os.path.exists("temp_processed_chunks.jsonl"):
                os.unlink("temp_processed_chunks.jsonl")
        except:
            pass

        return ProcessPDFResponse(
            success=False,
            message=f"æ–‡ä»¶è™•ç†å¤±æ•—: {str(e)}",
            chunks_processed=0,
            images_extracted=0,
            collection_name="",
            processing_time=time.time() - start_time,
            errors=[str(e)]
        )


@app.post("/process-pdf", response_model=ProcessPDFResponse)
async def process_pdf(
    file: UploadFile = File(..., description="PDFæ–‡ä»¶"),
    collection_name: Optional[str] = Query(None, description="è‡ªå®šç¾©é›†åˆåç¨±ï¼Œå¦‚ä¸æä¾›å‰‡ä½¿ç”¨é è¨­"),
    enable_vision: bool = Query(True, description="æ˜¯å¦å•Ÿç”¨è¦–è¦ºåˆ†æ"),
    force_recreate: bool = Query(False, description="æ˜¯å¦å¼·åˆ¶é‡æ–°å‰µå»ºé›†åˆ")
):
    """
    è™•ç†ä¸Šå‚³çš„PDFæ–‡ä»¶ä¸¦è‡ªå‹•embeddingåˆ°Qdrantï¼ˆå‘å¾Œå…¼å®¹ç«¯é»ï¼‰

    - **file**: è¦è™•ç†çš„PDFæ–‡ä»¶
    - **collection_name**: å¯é¸çš„è‡ªå®šç¾©é›†åˆåç¨±
    - **enable_vision**: æ˜¯å¦å•Ÿç”¨GPT-4oè¦–è¦ºåˆ†æ
    - **force_recreate**: æ˜¯å¦å¼·åˆ¶é‡æ–°å‰µå»ºå‘é‡é›†åˆ
    """
    # æª¢æŸ¥æ–‡ä»¶é¡å‹
    if not file.filename.lower().endswith('.pdf'):
        raise HTTPException(status_code=400, detail="åªæ”¯æ´PDFæ–‡ä»¶æ ¼å¼")

    # ç›´æ¥èª¿ç”¨æ–°çš„å¤šæ ¼å¼è™•ç†ç«¯é»
    return await process_file(file, collection_name, enable_vision, force_recreate)


@app.get("/collections", response_model=List[str])
async def list_collections():
    """ç²å–æ‰€æœ‰å¯ç”¨çš„Qdranté›†åˆåˆ—è¡¨"""
    try:
        if rag_system is None:
            raise HTTPException(status_code=500, detail="RAGç³»çµ±æœªåˆå§‹åŒ–")

        collections = rag_system.qdrant_client.get_collections()
        collection_names = [col.name for col in collections.collections]

        return collection_names

    except Exception as e:
        logger.error(f"ç²å–é›†åˆåˆ—è¡¨å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–é›†åˆåˆ—è¡¨å¤±æ•—: {str(e)}")

@app.delete("/collections/{collection_name}")
async def delete_collection(collection_name: str):
    """åˆªé™¤æŒ‡å®šçš„Qdranté›†åˆ"""
    try:
        if rag_system is None:
            raise HTTPException(status_code=500, detail="RAGç³»çµ±æœªåˆå§‹åŒ–")

        # æª¢æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
        collections = rag_system.qdrant_client.get_collections()
        collection_names = [col.name for col in collections.collections]

        if collection_name not in collection_names:
            raise HTTPException(status_code=404, detail=f"é›†åˆ '{collection_name}' ä¸å­˜åœ¨")

        # åˆªé™¤é›†åˆ
        rag_system.qdrant_client.delete_collection(collection_name)

        logger.info(f"å·²åˆªé™¤é›†åˆ: {collection_name}")
        return {"message": f"æˆåŠŸåˆªé™¤é›†åˆ '{collection_name}'"}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åˆªé™¤é›†åˆå¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"åˆªé™¤é›†åˆå¤±æ•—: {str(e)}")


@app.get("/collections/{collection_name}/count", response_model=CollectionCountResponse)
async def check_collection_count(collection_name: str):
    """æª¢æŸ¥æŒ‡å®šé›†åˆçš„æ•¸é‡è³‡è¨Š"""
    try:
        if rag_system is None:
            raise HTTPException(status_code=500, detail="RAGç³»çµ±æœªåˆå§‹åŒ–")

        # ä½¿ç”¨é›†åˆæ•¸é‡æª¢æŸ¥å™¨
        from check_collection_count import CollectionCountChecker
        checker = CollectionCountChecker(qdrant_url=rag_system.qdrant_url)

        result = checker.check_collection_count(collection_name)

        if result["success"]:
            collection_info = CollectionInfo(
                collection_name=result["collection_name"],
                vectors_count=result["vectors_count"],
                points_count=result["points_count"],
                status=result["status"],
                exists=result["exists"]
            )

            return CollectionCountResponse(
                success=True,
                collection_info=collection_info,
                last_activity=result.get("last_activity")
            )
        else:
            return CollectionCountResponse(
                success=False,
                error_message=result.get("error_message", "æœªçŸ¥éŒ¯èª¤"),
                last_activity=result.get("last_activity")
            )

    except Exception as e:
        logger.error(f"æª¢æŸ¥é›†åˆæ•¸é‡å¤±æ•—: {e}")
        return CollectionCountResponse(
            success=False,
            error_message=f"æª¢æŸ¥é›†åˆæ•¸é‡å¤±æ•—: {str(e)}",
            last_activity=time.time()
        )


@app.get("/collections/count/all")
async def check_all_collections_count():
    """æª¢æŸ¥æ‰€æœ‰é›†åˆçš„æ•¸é‡è³‡è¨Š"""
    try:
        if rag_system is None:
            raise HTTPException(status_code=500, detail="RAGç³»çµ±æœªåˆå§‹åŒ–")

        # ä½¿ç”¨é›†åˆæ•¸é‡æª¢æŸ¥å™¨
        from check_collection_count import CollectionCountChecker
        checker = CollectionCountChecker(qdrant_url=rag_system.qdrant_url)

        result = checker.check_all_collections()

        return {
            "success": result["success"],
            "total_collections": result.get("total_collections", 0),
            "summary": result.get("summary", {}),
            "collections": result.get("collections", []),
            "error_message": result.get("error_message"),
            "last_activity": result.get("last_activity", time.time())
        }

    except Exception as e:
        logger.error(f"æª¢æŸ¥æ‰€æœ‰é›†åˆæ•¸é‡å¤±æ•—: {e}")
        return {
            "success": False,
            "error_message": f"æª¢æŸ¥æ‰€æœ‰é›†åˆæ•¸é‡å¤±æ•—: {str(e)}",
            "total_collections": 0,
            "collections": [],
            "last_activity": time.time()
        }


@app.get("/collections/{collection_name}/statistics")
async def get_collection_statistics(collection_name: str):
    """ç²å–æŒ‡å®šé›†åˆçš„è©³ç´°çµ±è¨ˆè³‡è¨Š"""
    try:
        if rag_system is None:
            raise HTTPException(status_code=500, detail="RAGç³»çµ±æœªåˆå§‹åŒ–")

        # ä½¿ç”¨é›†åˆæ•¸é‡æª¢æŸ¥å™¨
        from check_collection_count import CollectionCountChecker
        checker = CollectionCountChecker(qdrant_url=rag_system.qdrant_url)

        result = checker.get_collection_statistics(collection_name)

        return result

    except Exception as e:
        logger.error(f"ç²å–é›†åˆçµ±è¨ˆå¤±æ•—: {e}")
        return {
            "success": False,
            "collection_name": collection_name,
            "error_message": f"ç²å–é›†åˆçµ±è¨ˆå¤±æ•—: {str(e)}",
            "last_activity": time.time()
        }

@app.post("/chat", response_model=ChatResponse)
async def chat_with_memory(request: ChatRequest):
    """
    å¸¶æœ‰è¨˜æ†¶åŠŸèƒ½çš„èŠå¤©API

    - **message**: ç”¨æˆ¶è¨Šæ¯
    - **session_id**: æœƒè©±IDï¼Œå¦‚ä¸æä¾›å‰‡è‡ªå‹•ç”Ÿæˆ
    - **use_rag**: æ˜¯å¦ä½¿ç”¨RAGæª¢ç´¢ç›¸é—œå…§å®¹
    - **top_k**: RAGæª¢ç´¢çš„æ–‡ä»¶æ•¸é‡
    """
    if rag_system is None:
        raise HTTPException(status_code=500, detail="RAGç³»çµ±æœªåˆå§‹åŒ–")

    try:
        # ç”Ÿæˆæˆ–ä½¿ç”¨æä¾›çš„session_id
        session_id = request.session_id or str(uuid.uuid4())

        # ç²å–æœƒè©±è¨˜æ†¶
        messages = memory_manager.get_session(session_id)

        # æ·»åŠ ç”¨æˆ¶è¨Šæ¯åˆ°è¨˜æ†¶
        memory_manager.add_message(session_id, "user", request.message)

        # æº–å‚™å›æ‡‰å…§å®¹
        response_content = ""
        sources = []
        rag_used = False
        image_urls = []

        # å¦‚æœå•Ÿç”¨RAGï¼Œæª¢ç´¢ç›¸é—œå…§å®¹
        if request.use_rag and rag_system.has_vector_data():
            try:
                # æª¢ç´¢ç›¸é—œæ–‡ä»¶æ®µè½
                retrieval_results = rag_system.retrieve_relevant_chunks(
                    query=request.message,
                    top_k=request.top_k
                )

                if retrieval_results:
                    rag_used = True

                    # æº–å‚™RAGä¸Šä¸‹æ–‡
                    rag_context_parts = []
                    for result in retrieval_results:
                        context_part = f"ã€{result.parent_chunk.topic}ã€‘\n{result.parent_chunk.content}"

                        # æ·»åŠ ç›¸é—œåœ–ç‰‡
                        if result.parent_chunk.has_images and result.parent_chunk.image_paths:
                            current_image_urls = []
                            for image_path in result.parent_chunk.image_paths:
                                # ä½¿ç”¨çµ±ä¸€çš„ URL ç”Ÿæˆå‡½æ•¸
                                image_url = get_image_url(image_path)
                                if image_url:
                                    current_image_urls.append(image_url)
                                    # æ·»åŠ åˆ°å…¨å±€åœ–ç‰‡URLåˆ—è¡¨ï¼ˆæœ€å¤š3å¼µï¼‰
                                    if image_url not in image_urls and len(image_urls) < 3:
                                        image_urls.append(image_url)

                            if current_image_urls:
                                context_part += f"\n\nç›¸é—œåœ–ç‰‡ï¼š\n" + "\n".join(current_image_urls)

                        rag_context_parts.append(context_part)

                    rag_context = "\n\n".join(rag_context_parts)

                    # æ·»åŠ RAGä¸Šä¸‹æ–‡åˆ°å°è©±
                    rag_message = f"""åŸºæ–¼ä»¥ä¸‹æ•™æå…§å®¹å›ç­”å•é¡Œï¼š

{rag_context}

ç”¨æˆ¶å•é¡Œï¼š{request.message}

è«‹çµåˆæ•™æå…§å®¹å’Œä¹‹å‰çš„å°è©±æ­·å²ä¾†å›ç­”ã€‚"""

                    # æš«æ™‚æ·»åŠ RAGä¸Šä¸‹æ–‡ï¼ˆä¸ä¿å­˜åˆ°è¨˜æ†¶ä¸­ï¼‰
                    temp_messages = messages + [{"role": "user", "content": rag_message}]

                    # æº–å‚™ä¾†æºè³‡è¨Š
                    for result in retrieval_results:
                        parent_chunk = result.parent_chunk
                        child_chunk = result.child_chunk

                        source_info = {
                            "page_num": child_chunk.page_num,
                            "page_range": parent_chunk.page_range,
                            "topic": parent_chunk.topic,
                            "sub_topic": child_chunk.sub_topic,
                            "content": child_chunk.content,
                            "content_type": child_chunk.content_type,
                            "keywords": child_chunk.keywords,
                            "similarity_score": result.similarity_score,
                            "relevance_reason": result.relevance_reason
                        }

                        # è™•ç†åœ–ç‰‡è³‡è¨Šï¼ˆå¾çˆ¶æ®µè½ï¼‰
                        if hasattr(parent_chunk, 'has_images') and parent_chunk.has_images:
                            image_url = None
                            image_paths = getattr(parent_chunk, 'image_paths', [])
                            if image_paths:
                                # ä½¿ç”¨ç¬¬ä¸€å€‹åœ–ç‰‡è·¯å¾‘
                                image_url = get_image_url(image_paths[0])

                            image_analyses = getattr(parent_chunk, 'image_analyses', [])
                            image_analysis = image_analyses[0] if image_analyses else ""

                            source_info["image_info"] = ImageInfo(
                                has_images=True,
                                image_url=image_url,
                                image_analysis=image_analysis,
                                technical_symbols=getattr(child_chunk, 'technical_symbols', [])
                            )
                        else:
                            source_info["image_info"] = ImageInfo(has_images=False)

                        sources.append(SourceInfo(**source_info))

                else:
                    # æ²’æœ‰æ‰¾åˆ°ç›¸é—œå…§å®¹ï¼Œä½¿ç”¨æ™®é€šå°è©±
                    temp_messages = messages

            except Exception as e:
                logger.warning(f"RAGæª¢ç´¢å¤±æ•—ï¼Œä½¿ç”¨æ™®é€šå°è©±: {e}")
                temp_messages = messages
        else:
            # ä¸ä½¿ç”¨RAGï¼Œç›´æ¥å°è©±
            temp_messages = messages

        # èª¿ç”¨OpenAI APIç”Ÿæˆå›æ‡‰
        from openai import OpenAI
        client = OpenAI(api_key=Config.OPENAI_API_KEY)

        completion = client.chat.completions.create(
            model=Config.OPENAI_MODEL,
            messages=temp_messages,
            max_tokens=Config.MAX_TOKENS,
            temperature=Config.TEMPERATURE
        )

        response_content = completion.choices[0].message.content

        # æ·»åŠ åŠ©æ‰‹å›æ‡‰åˆ°è¨˜æ†¶
        memory_manager.add_message(session_id, "assistant", response_content)

        # ç²å–æœƒè©±çµ±è¨ˆ
        session_summary = memory_manager.get_session_summary(session_id)

        logger.info(f"èŠå¤©å›æ‡‰å®Œæˆ - æœƒè©±: {session_id}, RAG: {rag_used}")

        return ChatResponse(
            response=response_content,
            session_id=session_id,
            message_count=session_summary["message_count"],
            total_tokens=session_summary["total_tokens"],
            sources=sources,
            rag_used=rag_used
        )

    except Exception as e:
        logger.error(f"èŠå¤©è™•ç†å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"èŠå¤©è™•ç†å¤±æ•—: {str(e)}")

@app.get("/sessions", response_model=List[str])
async def list_chat_sessions():
    """ç²å–æ‰€æœ‰èŠå¤©æœƒè©±IDåˆ—è¡¨"""
    try:
        sessions = memory_manager.list_sessions()
        return sessions
    except Exception as e:
        logger.error(f"ç²å–æœƒè©±åˆ—è¡¨å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–æœƒè©±åˆ—è¡¨å¤±æ•—: {str(e)}")

@app.get("/sessions/{session_id}", response_model=SessionInfo)
async def get_session_info(session_id: str):
    """ç²å–æŒ‡å®šæœƒè©±çš„è©³ç´°è³‡è¨Š"""
    try:
        summary = memory_manager.get_session_summary(session_id)

        return SessionInfo(
            session_id=session_id,
            exists=summary["exists"],
            message_count=summary.get("message_count", 0),
            total_tokens=summary.get("total_tokens", 0),
            last_activity=summary.get("last_activity")
        )
    except Exception as e:
        logger.error(f"ç²å–æœƒè©±è³‡è¨Šå¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–æœƒè©±è³‡è¨Šå¤±æ•—: {str(e)}")

@app.delete("/sessions/{session_id}")
async def clear_session(session_id: str):
    """æ¸…é™¤æŒ‡å®šæœƒè©±çš„è¨˜æ†¶"""
    try:
        summary = memory_manager.get_session_summary(session_id)
        if not summary["exists"]:
            raise HTTPException(status_code=404, detail=f"æœƒè©± '{session_id}' ä¸å­˜åœ¨")

        memory_manager.clear_session(session_id)
        logger.info(f"å·²æ¸…é™¤æœƒè©±è¨˜æ†¶: {session_id}")

        return {"message": f"æˆåŠŸæ¸…é™¤æœƒè©± '{session_id}' çš„è¨˜æ†¶"}
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ¸…é™¤æœƒè©±è¨˜æ†¶å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"æ¸…é™¤æœƒè©±è¨˜æ†¶å¤±æ•—: {str(e)}")

# ==================== æ¸¬è©¦è™•ç†å‡½æ•¸ ====================

async def handle_excel_mode(tester, excel_file: UploadFile):
    """è™•ç† Excel æ¨¡å¼ï¼šç„¡åœ–ç‰‡ç´”å•é¡Œæ¸¬è©¦"""
    try:
        # è®€å– Excel æ–‡ä»¶
        excel_content = await excel_file.read()
        df = pd.read_excel(io.BytesIO(excel_content))

        # æª¢æŸ¥ Excel æ ¼å¼
        if 'question' not in df.columns:
            raise HTTPException(
                status_code=400,
                detail="Excel æ–‡ä»¶å¿…é ˆåŒ…å« 'question' æ¬„ä½"
            )

        results = []
        for _, row in df.iterrows():
            question = row['question']

            # åŸ·è¡Œç´”å•é¡Œæ¸¬è©¦ï¼ˆç„¡åœ–ç‰‡ï¼‰
            result = await tester.run_question_only_test(question)
            results.append(result)

        return results

    except Exception as e:
        logger.error(f"Excel æ¨¡å¼è™•ç†å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"Excel è™•ç†å¤±æ•—: {str(e)}")

async def handle_folder_mode(tester, folder_path: str, num_images_per_category: int):
    """è™•ç†è³‡æ–™å¤¾æ¨¡å¼ï¼šæœ‰åœ–ç‰‡æ¸¬è©¦"""
    try:
        # æª¢æŸ¥è³‡æ–™å¤¾æ˜¯å¦å­˜åœ¨
        folder_full_path = Path(folder_path)
        if not folder_full_path.exists():
            raise HTTPException(status_code=404, detail=f"è³‡æ–™å¤¾ä¸å­˜åœ¨: {folder_path}")

        # ç²å–åœ–ç‰‡é¡åˆ¥
        categories = tester.rag_test.get_image_categories(str(folder_full_path))
        if not categories:
            raise HTTPException(status_code=400, detail="è³‡æ–™å¤¾ä¸­æ²’æœ‰æ‰¾åˆ°åœ–ç‰‡")

        # æ§‹å»ºé¸æ“‡å­—å…¸
        selection = {}
        for category in categories.keys():
            selection[category] = min(num_images_per_category, len(categories[category]))

        # åŸ·è¡Œæ¸¬è©¦
        results = tester.run_selected_tests(categories, selection)
        return results

    except Exception as e:
        logger.error(f"è³‡æ–™å¤¾æ¨¡å¼è™•ç†å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"è³‡æ–™å¤¾è™•ç†å¤±æ•—: {str(e)}")

# ==================== çµ±ä¸€æ¸¬è©¦ API ç«¯é» ====================

@app.post("/api/test", response_model=TestResponse)
async def unified_test(
    excel_file: Optional[UploadFile] = File(None),
    folder_path: Optional[str] = Form(None),
    num_images_per_category: int = Form(1)
):
    """
    çµ±ä¸€æ¸¬è©¦ API - è‡ªå‹•åˆ¤æ–·æ¨¡å¼
    - ä¸Šå‚³ Excel: ç„¡åœ–ç‰‡æ¨¡å¼ï¼ˆç´”å•é¡Œæ¸¬è©¦ï¼‰
    - æŒ‡å®šè³‡æ–™å¤¾: æœ‰åœ–ç‰‡æ¨¡å¼ï¼ˆåœ–ç‰‡+å•é¡Œç”Ÿæˆ+æ¸¬è©¦ï¼‰
    """
    try:
        # å°å…¥æ¸¬è©¦ç³»çµ±
        import sys
        sys.path.append('./test_RAG')
        from interactive_rag_test import InteractiveRAGTester

        # åˆå§‹åŒ–æ¸¬è©¦å™¨
        tester = InteractiveRAGTester()

        # åˆ¤æ–·æ¸¬è©¦æ¨¡å¼
        if excel_file:
            # Excel æ¨¡å¼ï¼šç„¡åœ–ç‰‡æ¸¬è©¦ï¼ˆç´”å•é¡Œï¼‰
            logger.info("ğŸ” æª¢æ¸¬åˆ° Excel æ–‡ä»¶ï¼Œä½¿ç”¨ç„¡åœ–ç‰‡æ¨¡å¼")
            results = await handle_excel_mode(tester, excel_file)
            test_mode = "excel_questions"

        elif folder_path:
            # è³‡æ–™å¤¾æ¨¡å¼ï¼šæœ‰åœ–ç‰‡æ¸¬è©¦
            logger.info("ğŸ” æª¢æ¸¬åˆ°è³‡æ–™å¤¾è·¯å¾‘ï¼Œä½¿ç”¨æœ‰åœ–ç‰‡æ¨¡å¼")
            results = await handle_folder_mode(tester, folder_path, num_images_per_category)
            test_mode = "folder_images"

        else:
            raise HTTPException(
                status_code=400,
                detail="è«‹æä¾› Excel æ–‡ä»¶æˆ–è³‡æ–™å¤¾è·¯å¾‘"
            )

        # ç”Ÿæˆæ¸¬è©¦ ID å’Œæ™‚é–“æˆ³
        test_id = f"{test_mode}_test_{int(time.time())}"
        timestamp = time.strftime('%Y%m%d_%H%M%S')

        # ç”Ÿæˆ HTML å ±å‘Š
        html_content = tester.generate_html_report_with_images(results, timestamp)
        html_filename = f"results/api_test_{timestamp}.html"

        # ç¢ºä¿ results ç›®éŒ„å­˜åœ¨
        Path("results").mkdir(exist_ok=True)

        # ä¿å­˜ HTML å ±å‘Š
        with open(html_filename, 'w', encoding='utf-8') as f:
            f.write(html_content)

        # è¨ˆç®—çµ±è¨ˆè³‡è¨Š
        total_tests = len(results)

        # å®‰å…¨åœ°è¨ˆç®—å¹³å‡åˆ†æ•¸
        valid_scores = [r.get('overall_score', 0.0) for r in results if isinstance(r.get('overall_score'), (int, float))]
        avg_score = sum(valid_scores) / len(valid_scores) if valid_scores else 0.0

        # å®‰å…¨åœ°è¨ˆç®—ç¸½æˆæœ¬
        total_cost = 0.0
        for r in results:
            cost_info = r.get('cost_info', {})
            if isinstance(cost_info, dict):
                total_cost += cost_info.get('total_cost', 0.0)

        # è½‰æ›çµæœæ ¼å¼
        test_results = []
        for result in results:
            # å®‰å…¨åœ°ç²å–çµæœå­—æ®µï¼Œæä¾›é è¨­å€¼
            test_results.append(TestResult(
                image_name=result.get('image_name', 'unknown'),
                category=result.get('category', 'unknown'),
                question=result.get('question', ''),
                rag_answer=result.get('rag_answer', ''),
                evaluation={
                    'technical_accuracy': result.get('technical_accuracy', 0.0),
                    'completeness': result.get('completeness', 0.0),
                    'clarity': result.get('clarity', 0.0),
                    'image_reference': result.get('image_reference', 0.0),
                    'overall_score': result.get('overall_score', 0.0)
                },
                cost_info=result.get('cost_info', {})
            ))

        return TestResponse(
            test_id=test_id,
            total_tests=total_tests,
            results=test_results,
            summary={
                'average_score': avg_score,
                'total_cost': total_cost,
                'categories_tested': list(selection.keys()),
                'images_per_category': selection
            },
            html_report_url=f"/api/v1/JH/{html_filename}"
        )

    except Exception as e:
        logger.error(f"æ¸¬è©¦å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"æ¸¬è©¦å¤±æ•—: {str(e)}")

if __name__ == "__main__":
    # é–‹ç™¼æ¨¡å¼é‹è¡Œ
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8006,
        reload=True,
        log_level="info"
    )
